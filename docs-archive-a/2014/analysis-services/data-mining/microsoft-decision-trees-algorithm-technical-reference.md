---
title: Technische Referenz für den Microsoft Decision Trees-Algorithmus | Microsoft-Dokumentation
ms.custom: ''
ms.date: 06/13/2017
ms.prod: sql-server-2014
ms.reviewer: ''
ms.technology: analysis-services
ms.topic: conceptual
helpviewer_keywords:
- MAXIMUM_INPUT_ATTRIBUTES parameter
- SPLIT_METHOD parameter
- MINIMUM_SUPPORT parameter
- MAXIMUM_OUTPUT_ATTRIBUTES parameter
- FORCED_REGRESSOR parameter
- decision tree algorithms [Analysis Services]
- decision trees [Analysis Services]
- COMPLEXITY_PENALTY parameter
- SCORE_METHOD parameter
ms.assetid: 1e9f7969-0aa6-465a-b3ea-57b8d1c7a1fd
author: minewiskan
ms.author: owend
ms.openlocfilehash: 0cd0cd3100d0ed1213183815ae41f17cee3baa68
ms.sourcegitcommit: ad4d92dce894592a259721a1571b1d8736abacdb
ms.translationtype: MT
ms.contentlocale: de-DE
ms.lasthandoff: 08/04/2020
ms.locfileid: "87619443"
---
# <a name="microsoft-decision-trees-algorithm-technical-reference"></a><span data-ttu-id="b175a-102">Technische Referenz für den Microsoft Decision Trees-Algorithmus</span><span class="sxs-lookup"><span data-stu-id="b175a-102">Microsoft Decision Trees Algorithm Technical Reference</span></span>
  <span data-ttu-id="b175a-103">Der [!INCLUDE[msCoName](../../includes/msconame-md.md)] Decision Trees-Algorithmus ist ein hybrider Algorithmus, der verschiedene Methoden zum Erstellen einer Struktur integriert und mehrere analytische Tasks, wie Regression, Klassifikation und Zuordnung, unterstützt.</span><span class="sxs-lookup"><span data-stu-id="b175a-103">The [!INCLUDE[msCoName](../../includes/msconame-md.md)] Decision Trees algorithm is a hybrid algorithm that incorporates different methods for creating a tree, and supports multiple analytic tasks, including regression, classification, and association.</span></span> <span data-ttu-id="b175a-104">Der Microsoft Decision Trees-Algorithmus unterstützt die Modellierung sowohl diskreter als auch fortlaufender Attribute.</span><span class="sxs-lookup"><span data-stu-id="b175a-104">The Microsoft Decision Trees algorithm supports modeling of both discrete and continuous attributes.</span></span>  
  
 <span data-ttu-id="b175a-105">In diesem Thema wird die Implementierung des Algorithmus erläutert und beschrieben, wie das Verhalten des Algorithmus für verschiedene Aufgaben angepasst wird. Ferner werden Links zu weiteren Informationen über das Abfragen von Entscheidungsstrukturmodellen zur Verfügung gestellt.</span><span class="sxs-lookup"><span data-stu-id="b175a-105">This topic explains the implementation of the algorithm, describes how to customize the behavior of the algorithm for different tasks, and provides links to additional information about querying decision tree models.</span></span>  
  
## <a name="implementation-of-the-decision-trees-algorithm"></a><span data-ttu-id="b175a-106">Implementierung des Decision Trees-Algorithmus</span><span class="sxs-lookup"><span data-stu-id="b175a-106">Implementation of the Decision Trees Algorithm</span></span>  
 <span data-ttu-id="b175a-107">Der Microsoft Decision Trees-Algorithmus wendet den Bayes-Ansatz zum Erlernen kausaler Interaktionsmodelle durch die Ermittlung ungefährer posteriorer Verteilungen für die Modelle an.</span><span class="sxs-lookup"><span data-stu-id="b175a-107">The Microsoft Decision Trees algorithm applies the Bayesian approach to learning causal interaction models by obtaining approximate posterior distributions for the models.</span></span> <span data-ttu-id="b175a-108">Eine ausführliche Erläuterung dieses Ansatzes finden Sie im Dokument auf der Website Microsoft Research durch [Speichern der Struktur und Parameter](https://go.microsoft.com/fwlink/?LinkId=237640&clcid=0x409).</span><span class="sxs-lookup"><span data-stu-id="b175a-108">For a detailed explanation of this approach, see the paper on the Microsoft Research site, by [Structure and Parameter Learning](https://go.microsoft.com/fwlink/?LinkId=237640&clcid=0x409).</span></span>  
  
 <span data-ttu-id="b175a-109">Die Methodologie zur Bewertung des Informationswerts der für das Lernen erforderlichen *vorherigen Informationen* basiert auf der Annahme der *Likelihood-Äquivalenz*.</span><span class="sxs-lookup"><span data-stu-id="b175a-109">The methodology for assessing the information value of the *priors* needed for learning is based on the assumption of *likelihood equivalence*.</span></span> <span data-ttu-id="b175a-110">Diese besagt, dass keine Daten bei der Unterscheidung von Netzwerkstrukturen helfen sollen, die andernfalls die gleichen Assertionen der bedingten Unabhängigkeit darstellen.</span><span class="sxs-lookup"><span data-stu-id="b175a-110">This assumption says that data should not help to discriminate network structures that otherwise represent the same assertions of conditional independence.</span></span> <span data-ttu-id="b175a-111">Für jeden Fall wird ein einzelnes vorheriges Bayes-Netzwerk und ein einziges Vertrauensmaß für dieses Netzwerk angenommen.</span><span class="sxs-lookup"><span data-stu-id="b175a-111">Each case is assumed to have a single Bayesian prior network and a single measure of confidence for that network.</span></span>  
  
 <span data-ttu-id="b175a-112">Mithilfe dieser vorherigen Netzwerke berechnet der Algorithmus die relativen *Posterior-Wahrscheinlichkeiten* der Netzwerkstrukturen anhand der aktuellen Trainingsdaten und identifiziert die Netzwerkstrukturen, die die höchsten Posterior-Wahrscheinlichkeiten besitzen.</span><span class="sxs-lookup"><span data-stu-id="b175a-112">Using these prior networks, the algorithm then computes the relative *posterior probabilities* of network structures given the current training data, and identifies the network structures that have the highest posterior probabilities.</span></span>  
  
 <span data-ttu-id="b175a-113">Der Microsoft Decision Trees-Algorithmus verwendet andere Methoden, um die beste Struktur zu berechnen.</span><span class="sxs-lookup"><span data-stu-id="b175a-113">The Microsoft Decision Trees algorithm uses different methods to compute the best tree.</span></span> <span data-ttu-id="b175a-114">Die verwendete Methode hängt vom Task ab, der entweder die lineare Regressions-, die Klassifizierungs- oder die Zuordnungsanalyse sein kann.</span><span class="sxs-lookup"><span data-stu-id="b175a-114">The method used depends on the task, which can be linear regression, classification, or association analysis.</span></span> <span data-ttu-id="b175a-115">Ein einzelnes Modell kann mehrere Strukturen für andere vorhersagbare Attribute enthalten.</span><span class="sxs-lookup"><span data-stu-id="b175a-115">A single model can contain multiple trees for different predictable attributes.</span></span> <span data-ttu-id="b175a-116">Darüber hinaus kann jede Struktur mehrere Verzweigungen enthalten. Dies hängt davon ab, wie viele Attribute und Werte in den Daten vorhanden sind.</span><span class="sxs-lookup"><span data-stu-id="b175a-116">Moreover, each tree can contain multiple branches, depending on how many attributes and values there are in the data.</span></span> <span data-ttu-id="b175a-117">Die Form und Tiefe der Struktur eines bestimmten Modells hängt von der Bewertungsmethode und anderen verwendeten Parametern ab.</span><span class="sxs-lookup"><span data-stu-id="b175a-117">The shape and depth of the tree built in a particular model depends on the scoring method and other parameters that were used.</span></span> <span data-ttu-id="b175a-118">Änderungen in den Parametern können auch beeinflussen, wo die Knoten sich teilen.</span><span class="sxs-lookup"><span data-stu-id="b175a-118">Changes in the parameters can also affect where the nodes split.</span></span>  
  
### <a name="building-the-tree"></a><span data-ttu-id="b175a-119">Erstellen der Struktur</span><span class="sxs-lookup"><span data-stu-id="b175a-119">Building the Tree</span></span>  
 <span data-ttu-id="b175a-120">Wenn der Microsoft Decision Trees-Algorithmus die Menge möglicher Eingabewerte erstellt, führt er *feature selection* aus, um die Attribute zu identifizieren, die die meisten Informationen liefern, und berücksichtigt die Werte nicht mehr, die äußerst selten sind.</span><span class="sxs-lookup"><span data-stu-id="b175a-120">When the Microsoft Decision Trees algorithm creates the set of possible input values, it performs *feature selection* to identify the attributes and values that provide the most information, and removes from consideration the values that are very rare.</span></span> <span data-ttu-id="b175a-121">Der Algorithmus gruppiert außerdem Werte in *Container*, um Gruppen von Werten zu erstellen, die zur Optimierung der Leistung als eine Einheit verarbeitet werden können.</span><span class="sxs-lookup"><span data-stu-id="b175a-121">The algorithm also groups values into *bins*, to create groupings of values that can be processed as a unit to optimize performance.</span></span>  
  
 <span data-ttu-id="b175a-122">Eine Struktur wird erstellt, indem die Korrelationen zwischen einer Eingabe und dem gewünschten Ergebnis bestimmt werden.</span><span class="sxs-lookup"><span data-stu-id="b175a-122">A tree is built by determining the correlations between an input and the targeted outcome.</span></span> <span data-ttu-id="b175a-123">Nachdem alle Attribute mit Korrelationen versehen wurden, identifiziert der Algorithmus das einzige Attribut, das die Ergebnisse am saubersten trennt.</span><span class="sxs-lookup"><span data-stu-id="b175a-123">After all the attributes have been correlated, the algorithm identifies the single attribute that most cleanly separates the outcomes.</span></span> <span data-ttu-id="b175a-124">Dieser Punkt der besten Trennung wird mit einer Gleichung gemessen, die den Informationsgewinn berechnet.</span><span class="sxs-lookup"><span data-stu-id="b175a-124">This point of the best separation is measured by using an equation that calculates information gain.</span></span> <span data-ttu-id="b175a-125">Das Attribut, das das beste Ergebnis für den Informationsgewinn aufweist, wird zum Teilen der Fälle in Teilmengen verwendet. Diese Teilmengen werden anschließend vom gleichen Prozess rekursiv analysiert, bis die Struktur nicht weiter aufgeteilt werden kann.</span><span class="sxs-lookup"><span data-stu-id="b175a-125">The attribute that has the best score for information gain is used to divide the cases into subsets, which are then recursively analyzed by the same process, until the tree cannot be split any more.</span></span>  
  
 <span data-ttu-id="b175a-126">Die präzise Gleichung zur Bewertung des Informationsgewinns hängt von den beim Erstellen des Algorithmus festgelegten Parametern, vom Datentyp der vorhersagbaren Spalte und vom Datentyp der Eingabe ab.</span><span class="sxs-lookup"><span data-stu-id="b175a-126">The exact equation used to evaluate information gain depends on the parameters set when you created the algorithm, the data type of the predictable column, and the data type of the input.</span></span>  
  
### <a name="discrete-and-continuous-inputs"></a><span data-ttu-id="b175a-127">Diskrete und kontinuierliche Eingaben</span><span class="sxs-lookup"><span data-stu-id="b175a-127">Discrete and Continuous Inputs</span></span>  
 <span data-ttu-id="b175a-128">Wenn das vorhersagbare Attribut diskret ist und die Eingaben diskret sind, wird die Zählung der Ausgaben je Eingabe durch Erstellen einer Matrix und Generieren von Bewertungen für jede Zelle in der Matrix vorgenommen.</span><span class="sxs-lookup"><span data-stu-id="b175a-128">When the predictable attribute is discrete and the inputs are discrete, counting the outcomes per input is a matter of creating a matrix and generating scores for each cell in the matrix.</span></span>  
  
 <span data-ttu-id="b175a-129">Wenn hingegen das vorhersagbare Attribut diskret ist und die Eingaben kontinuierlich sind, wird die Eingabe der kontinuierlichen Spalten automatisch diskretisiert.</span><span class="sxs-lookup"><span data-stu-id="b175a-129">However, when the predictable attribute is discrete and the inputs are continuous, the input of the continuous columns are automatically discretized.</span></span> <span data-ttu-id="b175a-130">Sie können die Standardeinstellung übernehmen und die optimale Anzahl von Containern durch [!INCLUDE[ssASnoversion](../../includes/ssasnoversion-md.md)] ermitteln lassen, oder Sie können die Art und Weise steuern, wie kontinuierliche Eingaben diskretisiert werden, indem Sie die <xref:Microsoft.AnalysisServices.ScalarMiningStructureColumn.DiscretizationMethod%2A> - und die <xref:Microsoft.AnalysisServices.ScalarMiningStructureColumn.DiscretizationBucketCount%2A> -Eigenschaft festlegen.</span><span class="sxs-lookup"><span data-stu-id="b175a-130">You can accept the default and have [!INCLUDE[ssASnoversion](../../includes/ssasnoversion-md.md)] find the optimum number of bins, or you can control the manner in which continuous inputs are discretized by setting the <xref:Microsoft.AnalysisServices.ScalarMiningStructureColumn.DiscretizationMethod%2A> and <xref:Microsoft.AnalysisServices.ScalarMiningStructureColumn.DiscretizationBucketCount%2A> properties.</span></span> <span data-ttu-id="b175a-131">Weitere Informationen finden Sie unter [Ändern der Diskretisierung von Spalten in Miningmodellen](change-the-discretization-of-a-column-in-a-mining-model.md).</span><span class="sxs-lookup"><span data-stu-id="b175a-131">For more information, see [Change the Discretization of a Column in a Mining Model](change-the-discretization-of-a-column-in-a-mining-model.md).</span></span>  
  
 <span data-ttu-id="b175a-132">Bei kontinuierlichen Attributen bestimmt der Algorithmus anhand einer linearen Regression, wo sich die Entscheidungsstruktur teilt.</span><span class="sxs-lookup"><span data-stu-id="b175a-132">For continuous attributes, the algorithm uses linear regression to determine where a decision tree splits.</span></span>  
  
 <span data-ttu-id="b175a-133">Wenn es sich bei dem vorhersagbaren Attribut um einen kontinuierlichen numerischen Datentyp handelt, wird die Funktionsauswahl auch auf die Ausgaben angewendet, um die mögliche Zahl von Ausgaben zu reduzieren und das Modell schneller zu erstellen.</span><span class="sxs-lookup"><span data-stu-id="b175a-133">When the predictable attribute is a continuous numeric data type, feature selection is applied to the outputs as well, to reduce the possible number of outcomes and build the model faster.</span></span> <span data-ttu-id="b175a-134">Sie können den Schwellenwert für die Funktionsauswahl ändern und so die Zahl der möglichen Werte erhöhen oder reduzieren, indem Sie den MAXIMUM_OUTPUT_ATTRIBUTES-Parameter festlegen.</span><span class="sxs-lookup"><span data-stu-id="b175a-134">You can change the threshold for feature selection and thereby increase or decrease the number of possible values by setting the MAXIMUM_OUTPUT_ATTRIBUTES parameter.</span></span>  
  
 <span data-ttu-id="b175a-135">Eine ausführlichere Erläuterung zur Funktionsweise des [!INCLUDE[msCoName](../../includes/msconame-md.md)] Decision Trees-Algorithmus im Zusammenhang mit diskreten vorhersagbaren Spalten finden Sie unter [Learning Bayesian Networks: The Combination of Knowledge and Statistical Data](https://go.microsoft.com/fwlink/?LinkId=45963).</span><span class="sxs-lookup"><span data-stu-id="b175a-135">For a more detained explanation about how the [!INCLUDE[msCoName](../../includes/msconame-md.md)] Decision Trees algorithm works with discrete predictable columns, see [Learning Bayesian Networks: The Combination of Knowledge and Statistical Data](https://go.microsoft.com/fwlink/?LinkId=45963).</span></span> <span data-ttu-id="b175a-136">Weitere Informationen zur Funktionsweise des [!INCLUDE[msCoName](../../includes/msconame-md.md)] Decision Trees-Algorithmus im Zusammenhang mit kontinuierlichen vorhersagbaren Spalten finden Sie im Anhang des Dokuments [Autoregressive Tree Models for Time-Series Analysis](https://go.microsoft.com/fwlink/?LinkId=45966)(Autoregressive Strukturmodelle zur Zeitreihenanalyse).</span><span class="sxs-lookup"><span data-stu-id="b175a-136">For more information about how the [!INCLUDE[msCoName](../../includes/msconame-md.md)] Decision Trees algorithm works with a continuous predictable column, see the appendix of [Autoregressive Tree Models for Time-Series Analysis](https://go.microsoft.com/fwlink/?LinkId=45966).</span></span>  
  
### <a name="scoring-methods-and-feature-selection"></a><span data-ttu-id="b175a-137">Bewertungsmethoden und Funktionsauswahl</span><span class="sxs-lookup"><span data-stu-id="b175a-137">Scoring Methods and Feature Selection</span></span>  
 <span data-ttu-id="b175a-138">Der Microsoft Decision Trees-Algorithmus bietet drei Formeln zur Bewertung des Informationsgewinns: Shannon-Entropie, Bayes-Methode mit K2-A-priori-Verteilung und Bayes-Netzwerk mit einheitlicher Dirichlet-Verteilung von A-priori-Zuständen.</span><span class="sxs-lookup"><span data-stu-id="b175a-138">The Microsoft Decision Trees algorithm offers three formulas for scoring information gain: Shannon's entropy, Bayesian network with K2 prior, and Bayesian network with a uniform Dirichlet distribution of priors.</span></span> <span data-ttu-id="b175a-139">Alle drei Methoden sind im Data Mining-Bereich etabliert.</span><span class="sxs-lookup"><span data-stu-id="b175a-139">All three methods are well established in the data mining field.</span></span> <span data-ttu-id="b175a-140">Es wird empfohlen, mit verschiedenen Parametern und Bewertungsmethoden zu experimentieren, um festzustellen, welche die besten Ergebnisse erzielen.</span><span class="sxs-lookup"><span data-stu-id="b175a-140">We recommend that you experiment with different parameters and scoring methods to determine which provides the best results.</span></span> <span data-ttu-id="b175a-141">Weitere Informationen zu diesen Bewertungsmethoden finden Sie unter [Feature Selection](../../sql-server/install/feature-selection.md).</span><span class="sxs-lookup"><span data-stu-id="b175a-141">For more information about these scoring methods, see [Feature Selection](../../sql-server/install/feature-selection.md).</span></span>  
  
 <span data-ttu-id="b175a-142">Die Funktionsauswahl wird automatisch von allen [!INCLUDE[ssASnoversion](../../includes/ssasnoversion-md.md)] Data Mining-Algorithmen zur Verbesserung der Analyse und zur Reduzierung der Verarbeitungslast verwendet.</span><span class="sxs-lookup"><span data-stu-id="b175a-142">All [!INCLUDE[ssASnoversion](../../includes/ssasnoversion-md.md)] data mining algorithms automatically use feature selection to improve analysis and reduce processing load.</span></span> <span data-ttu-id="b175a-143">Die für die Funktionsauswahl verwendete Methode hängt vom Algorithmus ab, mit dem das Modell erstellt wird.</span><span class="sxs-lookup"><span data-stu-id="b175a-143">The method used for feature selection depends on the algorithm that is used to build the model.</span></span> <span data-ttu-id="b175a-144">Die Algorithmusparameter, die die Funktionsauswahl für ein Entscheidungsstrukturmodell steuern, sind MAXIMUM_INPUT_ATTRIBUTES und MAXIMUM_OUTPUT.</span><span class="sxs-lookup"><span data-stu-id="b175a-144">The algorithm parameters that control feature selection for a decision trees model are MAXIMUM_INPUT_ATTRIBUTES and MAXIMUM_OUTPUT.</span></span>  
  
|<span data-ttu-id="b175a-145">Algorithmus</span><span class="sxs-lookup"><span data-stu-id="b175a-145">Algorithm</span></span>|<span data-ttu-id="b175a-146">Analysemethode</span><span class="sxs-lookup"><span data-stu-id="b175a-146">Method of analysis</span></span>|<span data-ttu-id="b175a-147">Kommentare</span><span class="sxs-lookup"><span data-stu-id="b175a-147">Comments</span></span>|  
|---------------|------------------------|--------------|  
|<span data-ttu-id="b175a-148">Entscheidungsstrukturen</span><span class="sxs-lookup"><span data-stu-id="b175a-148">Decision Trees</span></span>|<span data-ttu-id="b175a-149">Interessantheitsgrad</span><span class="sxs-lookup"><span data-stu-id="b175a-149">Interestingness score</span></span><br /><br /> <span data-ttu-id="b175a-150">Shannon-Entropie</span><span class="sxs-lookup"><span data-stu-id="b175a-150">Shannon's Entropy</span></span><br /><br /> <span data-ttu-id="b175a-151">Bayes-Methode mit K2-A-priori-Verteilung</span><span class="sxs-lookup"><span data-stu-id="b175a-151">Bayesian with K2 Prior</span></span><br /><br /> <span data-ttu-id="b175a-152">Bayes-Dirichlet mit uniformer A-priori-Verteilung (Standard)</span><span class="sxs-lookup"><span data-stu-id="b175a-152">Bayesian Dirichlet with uniform prior (default)</span></span>|<span data-ttu-id="b175a-153">Wenn irgendeine Spalte nicht binäre kontinuierliche Werte enthält, wird der Interessantheitsgrad für alle Spalten verwendet, um die Konsistenz zu gewährleisten.</span><span class="sxs-lookup"><span data-stu-id="b175a-153">If any columns contain non-binary continuous values, the interestingness score is used for all columns, to ensure consistency.</span></span> <span data-ttu-id="b175a-154">Andernfalls wird die Standardmethode oder die angegebene Methode verwendet.</span><span class="sxs-lookup"><span data-stu-id="b175a-154">Otherwise, the default or specified method is used.</span></span>|  
|<span data-ttu-id="b175a-155">Lineare Regression</span><span class="sxs-lookup"><span data-stu-id="b175a-155">Linear Regression</span></span>|<span data-ttu-id="b175a-156">Interessantheitsgrad</span><span class="sxs-lookup"><span data-stu-id="b175a-156">Interestingness score</span></span>|<span data-ttu-id="b175a-157">Der Linear Regression-Algorithmus verwendet nur den Interessantheitsgrad, da er nur kontinuierliche Spalten unterstützt.</span><span class="sxs-lookup"><span data-stu-id="b175a-157">Linear Regression only uses interestingness, because it only supports continuous columns.</span></span>|  
  
### <a name="scalability-and-performance"></a><span data-ttu-id="b175a-158">Skalierbarkeit und Leistung</span><span class="sxs-lookup"><span data-stu-id="b175a-158">Scalability and Performance</span></span>  
 <span data-ttu-id="b175a-159">Die Klassifizierung ist eine wichtige Data Mining-Strategie.</span><span class="sxs-lookup"><span data-stu-id="b175a-159">Classification is an important data mining strategy.</span></span> <span data-ttu-id="b175a-160">Im Allgemeinen steigt die Menge an Informationen, die zur Klassifizierung der Fälle erforderlich ist, direkt proportional zur Anzahl der Eingabedatensätze.</span><span class="sxs-lookup"><span data-stu-id="b175a-160">Generally, the amount of information that is needed to classify the cases grows in direct proportion to the number of input records.</span></span> <span data-ttu-id="b175a-161">Dies schränkt den Umfang der Daten ein, die klassifiziert werden können.</span><span class="sxs-lookup"><span data-stu-id="b175a-161">This limits the size of the data that can be classified.</span></span> <span data-ttu-id="b175a-162">Der Microsoft Decision Trees-Algorithmus verwendet die folgenden Methoden, um diese Probleme zu lösen, die Leistung zu verbessern und Speicherbeschränkungen aufzuheben:</span><span class="sxs-lookup"><span data-stu-id="b175a-162">The Microsoft Decision Trees algorithm using uses the following methods to resolve these problems, improve performance, and eliminate memory restrictions:</span></span>  
  
-   <span data-ttu-id="b175a-163">Funktionsauswahl zur Optimierung der Auswahl von Attributen.</span><span class="sxs-lookup"><span data-stu-id="b175a-163">Feature selection to optimize the selection of attributes.</span></span>  
  
-   <span data-ttu-id="b175a-164">Bayes-Bewertung zur Kontrolle der Strukturzunahme.</span><span class="sxs-lookup"><span data-stu-id="b175a-164">Bayesian scoring to control tree growth.</span></span>  
  
-   <span data-ttu-id="b175a-165">Optimierung der Klasseneinteilung für kontinuierliche Attribute.</span><span class="sxs-lookup"><span data-stu-id="b175a-165">Optimization of binning for continuous attributes.</span></span>  
  
-   <span data-ttu-id="b175a-166">Dynamische Gruppierung von Eingabewerten zur Bestimmung der wichtigsten Werte.</span><span class="sxs-lookup"><span data-stu-id="b175a-166">Dynamic grouping of input values to determine the most important values.</span></span>  
  
 <span data-ttu-id="b175a-167">Der Microsoft Decision Trees-Algorithmus ist schnell und skalierbar und ist auf eine einfache Parallelisierung ausgelegt. Dies bedeutet, dass alle Prozessoren zusammenarbeiten, um ein einzelnes, konsistentes Modell zu erstellen.</span><span class="sxs-lookup"><span data-stu-id="b175a-167">The Microsoft Decision Trees algorithm is fast and scalable, and has been designed to be easily parallelized, meaning that all processors work together to build a single, consistent model.</span></span> <span data-ttu-id="b175a-168">Die Kombination dieser Eigenschaften macht die Entscheidungsstrukturklassifizierung zu einem idealen Tool für Data Mining.</span><span class="sxs-lookup"><span data-stu-id="b175a-168">The combination of these characteristics makes the decision-tree classifier an ideal tool for data mining.</span></span>  
  
 <span data-ttu-id="b175a-169">Wenn schwerwiegende Leistungseinschränkungen vorliegen, können Sie die Verarbeitungszeit während des Trainings eines Entscheidungsstrukturmodells mit den folgenden Methoden verbessern.</span><span class="sxs-lookup"><span data-stu-id="b175a-169">If performance constraints are severe, you might be able to improve processing time during the training of a decision tree model by using the following methods.</span></span> <span data-ttu-id="b175a-170">Beachten Sie in diesem Fall jedoch, dass durch Entfernen von Attributen zur Verbesserung der Verarbeitungsleistung die Ergebnisse des Modells verändert werden und möglicherweise für die Gesamtpopulation weniger repräsentativ sind.</span><span class="sxs-lookup"><span data-stu-id="b175a-170">However, if you do so, be aware that eliminating attributes to improve processing performance will change the results of the model, and possibly make it less representative of the total population.</span></span>  
  
-   <span data-ttu-id="b175a-171">Erhöhen Sie den Wert des COMPLEXITY_PENALTY-Parameters, um die Strukturzunahme einzuschränken.</span><span class="sxs-lookup"><span data-stu-id="b175a-171">Increase the value of the COMPLEXITY_PENALTY parameter to limit tree growth.</span></span>  
  
-   <span data-ttu-id="b175a-172">Schränken Sie die Anzahl von Elementen in Zuordnungsmodellen ein, um die Anzahl von Strukturen zu begrenzen, die erstellt werden.</span><span class="sxs-lookup"><span data-stu-id="b175a-172">Limit the number of items in association models to limit the number of trees that are built.</span></span>  
  
-   <span data-ttu-id="b175a-173">Erhöhen Sie den Wert des MINIMUM_SUPPORT-Parameters, um Überanpassung zu vermeiden.</span><span class="sxs-lookup"><span data-stu-id="b175a-173">Increase the value of the MINIMUM_SUPPORT parameter to avoid overfitting.</span></span>  
  
-   <span data-ttu-id="b175a-174">Beschränken Sie die Anzahl von diskreten Werten für ein Attribut auf 10 oder weniger.</span><span class="sxs-lookup"><span data-stu-id="b175a-174">Restrict the number of discrete values for any attribute to 10 or less.</span></span> <span data-ttu-id="b175a-175">Sie könnten versuchen, Werte auf andere Weisen in anderen Modellen zu gruppieren.</span><span class="sxs-lookup"><span data-stu-id="b175a-175">You might try grouping values in different ways in different models.</span></span>  
  
    > [!NOTE]  
    >  <span data-ttu-id="b175a-176">Mit den in  [!INCLUDE[ssISCurrent](../../includes/ssiscurrent-md.md)] verfügbaren Tools zum Durchsuchen von Daten können Sie die Verteilung der Werte in Ihren Daten visuell darstellen und die Daten vor Beginn des Data Mining-Vorgangs entsprechend gruppieren.</span><span class="sxs-lookup"><span data-stu-id="b175a-176">You can use the data exploration tools available in  [!INCLUDE[ssISCurrent](../../includes/ssiscurrent-md.md)] to visualize the distribution of values in your data and group your values appropriately before beginning data mining.</span></span> <span data-ttu-id="b175a-177">Weitere Informationen finden Sie unter [Datenprofilerstellungs-Task und -Viewer](../../integration-services/control-flow/data-profiling-task-and-viewer.md).</span><span class="sxs-lookup"><span data-stu-id="b175a-177">For more information, see [Data Profiling Task and Viewer](../../integration-services/control-flow/data-profiling-task-and-viewer.md).</span></span> <span data-ttu-id="b175a-178">Sie können auch die [Data Mining-Add-Ins für Excel 2007](https://www.microsoft.com/download/details.aspx?id=8569)verwenden, um Daten in Microsoft Excel zu durchsuchen, zu gruppieren und mit neuen Bezeichnungen versehen.</span><span class="sxs-lookup"><span data-stu-id="b175a-178">You can also use the [Data Mining Add-ins for Excel 2007](https://www.microsoft.com/download/details.aspx?id=8569), to explore, group and relabel data in Microsoft Excel.</span></span>  
  
## <a name="customizing-the-decision-trees-algorithm"></a><span data-ttu-id="b175a-179">Anpassen des Decision Trees-Algorithmus</span><span class="sxs-lookup"><span data-stu-id="b175a-179">Customizing the Decision Trees Algorithm</span></span>  
 <span data-ttu-id="b175a-180">Der [!INCLUDE[msCoName](../../includes/msconame-md.md)] Decision Trees-Algorithmus unterstützt Parameter, die sich auf die Leistung und Genauigkeit des resultierenden Miningmodells auswirken.</span><span class="sxs-lookup"><span data-stu-id="b175a-180">The [!INCLUDE[msCoName](../../includes/msconame-md.md)] Decision Trees algorithm supports parameters that affect the performance and accuracy of the resulting mining model.</span></span> <span data-ttu-id="b175a-181">Sie können außerdem Modellierungsflags für die Miningmodellspalten oder Miningstrukturspalten festlegen, um die Verarbeitung der Daten zu steuern.</span><span class="sxs-lookup"><span data-stu-id="b175a-181">You can also set modeling flags on the mining model columns or mining structure columns to control the way that data is processed.</span></span>  
  
> [!NOTE]  
>  <span data-ttu-id="b175a-182">Der Microsoft Decision Trees-Algorithmus ist in allen Editionen von [!INCLUDE[ssNoVersion](../../includes/ssnoversion-md.md)]verfügbar, einige erweiterte Parameter, mit denen das Verhalten des Microsoft Decision Trees-Algorithmus angepasst werden kann, stehen jedoch nur in bestimmten Editionen von [!INCLUDE[ssNoVersion](../../includes/ssnoversion-md.md)]zur Verfügung.</span><span class="sxs-lookup"><span data-stu-id="b175a-182">The Microsoft Decision Trees algorithm is available in all editions of [!INCLUDE[ssNoVersion](../../includes/ssnoversion-md.md)]; however, some advanced parameters for customizing the behavior of the Microsoft Decision Trees algorithm are available for use only in specific editions of [!INCLUDE[ssNoVersion](../../includes/ssnoversion-md.md)].</span></span> <span data-ttu-id="b175a-183">Eine Liste der Funktionen, die von den-Editionen unterstützt werden [!INCLUDE[ssNoVersion](../../includes/ssnoversion-md.md)] , finden Sie [unter von den-Editionen unterstützte Funktionen SQL Server 2012](https://go.microsoft.com/fwlink/?linkid=232473) () https://go.microsoft.com/fwlink/?linkid=232473) .</span><span class="sxs-lookup"><span data-stu-id="b175a-183">For a list of features that are supported by the editions of [!INCLUDE[ssNoVersion](../../includes/ssnoversion-md.md)], see [Features Supported by the Editions of SQL Server 2012](https://go.microsoft.com/fwlink/?linkid=232473) (https://go.microsoft.com/fwlink/?linkid=232473).</span></span>  
  
### <a name="setting-algorithm-parameters"></a><span data-ttu-id="b175a-184">Festlegen von Algorithmusparametern</span><span class="sxs-lookup"><span data-stu-id="b175a-184">Setting Algorithm Parameters</span></span>  
 <span data-ttu-id="b175a-185">In der folgenden Tabelle sind die Parameter beschrieben, die mit dem [!INCLUDE[msCoName](../../includes/msconame-md.md)] Decision Trees-Algorithmus verwendet werden können.</span><span class="sxs-lookup"><span data-stu-id="b175a-185">The following table describes the parameters that you can use with the [!INCLUDE[msCoName](../../includes/msconame-md.md)] Decision Trees algorithm.</span></span>  
  
 <span data-ttu-id="b175a-186">*COMPLEXITY_PENALTY*</span><span class="sxs-lookup"><span data-stu-id="b175a-186">*COMPLEXITY_PENALTY*</span></span>  
 <span data-ttu-id="b175a-187">Steuert das Anwachsen der Entscheidungsstruktur.</span><span class="sxs-lookup"><span data-stu-id="b175a-187">Controls the growth of the decision tree.</span></span> <span data-ttu-id="b175a-188">Ein niedriger Wert führt zu einer größeren Anzahl von Teilungen, und ein hoher Wert führt zu einer niedrigeren Anzahl von Teilungen.</span><span class="sxs-lookup"><span data-stu-id="b175a-188">A low value increases the number of splits, and a high value decreases the number of splits.</span></span> <span data-ttu-id="b175a-189">Der Standardwert richtet sich nach der Anzahl von Attributen in einem bestimmten Modell und ist der nachstehenden Liste zu entnehmen:</span><span class="sxs-lookup"><span data-stu-id="b175a-189">The default value is based on the number of attributes for a particular model, as described in the following list:</span></span>  
  
-   <span data-ttu-id="b175a-190">Für die Attribute 1-9 lautet der Wert 0,5.</span><span class="sxs-lookup"><span data-stu-id="b175a-190">For 1 through 9 attributes, the default is 0.5.</span></span>  
  
-   <span data-ttu-id="b175a-191">Für 10 bis 99 Attribute lautet der Wert 0,9.</span><span class="sxs-lookup"><span data-stu-id="b175a-191">For 10 through 99 attributes, the default is 0.9.</span></span>  
  
-   <span data-ttu-id="b175a-192">Für 100 oder mehr Attribute lautet der Wert 0,99.</span><span class="sxs-lookup"><span data-stu-id="b175a-192">For 100 or more attributes, the default is 0.99.</span></span>  
  
 <span data-ttu-id="b175a-193">*FORCE_REGRESSOR*</span><span class="sxs-lookup"><span data-stu-id="b175a-193">*FORCE_REGRESSOR*</span></span>  
 <span data-ttu-id="b175a-194">Zwingt den Algorithmus, die angegebenen Spalten als Regressoren zu verwenden, unabhängig von ihrer durch den Algorithmus berechneten Wichtigkeit der Spalten.</span><span class="sxs-lookup"><span data-stu-id="b175a-194">Forces the algorithm to use the specified columns as regressors, regardless of the importance of the columns as calculated by the algorithm.</span></span> <span data-ttu-id="b175a-195">Dieser Parameter wird nur für Entscheidungsstrukturen verwendet, die ein kontinuierliches Attribut vorhersagen.</span><span class="sxs-lookup"><span data-stu-id="b175a-195">This parameter is only used for decision trees that are predicting a continuous attribute.</span></span>  
  
> [!NOTE]  
>  <span data-ttu-id="b175a-196">Durch Festlegen dieses Parameters wird der Algorithmus gezwungen, zu versuchen, das Attribut als Regressor zu verwenden.</span><span class="sxs-lookup"><span data-stu-id="b175a-196">By setting this parameter, you force the algorithm to try to use the attribute as a regressor.</span></span> <span data-ttu-id="b175a-197">Ob das Attribut im endgültigen Modell tatsächlich als Regressor verwendet wird, hängt von den Analyseergebnissen ab.</span><span class="sxs-lookup"><span data-stu-id="b175a-197">However, whether the attribute is actually used as a regressor in the final model depends on the results of analysis.</span></span> <span data-ttu-id="b175a-198">Sie können feststellen, welche Spalten als Regressoren verwendet wurden, indem Sie den Modellinhalt abfragen.</span><span class="sxs-lookup"><span data-stu-id="b175a-198">You can find out which columns were used as regressors by querying the model content.</span></span>  
  
 <span data-ttu-id="b175a-199">[Nur in einigen Editionen von [!INCLUDE[ssNoVersion](../../includes/ssnoversion-md.md)] verfügbar]</span><span class="sxs-lookup"><span data-stu-id="b175a-199">[Available only in some editions of [!INCLUDE[ssNoVersion](../../includes/ssnoversion-md.md)] ]</span></span>  
  
 <span data-ttu-id="b175a-200">*MAXIMUM_INPUT_ATTRIBUTES*</span><span class="sxs-lookup"><span data-stu-id="b175a-200">*MAXIMUM_INPUT_ATTRIBUTES*</span></span>  
 <span data-ttu-id="b175a-201">Definiert die Anzahl von Eingabeattributen, die der Algorithmus verarbeiten kann, bevor die Funktionsauswahl aufgerufen wird.</span><span class="sxs-lookup"><span data-stu-id="b175a-201">Defines the number of input attributes that the algorithm can handle before it invokes feature selection.</span></span>  
  
 <span data-ttu-id="b175a-202">Der Standardwert ist 255.</span><span class="sxs-lookup"><span data-stu-id="b175a-202">The default is 255.</span></span>  
  
 <span data-ttu-id="b175a-203">Legen Sie diesen Wert auf 0 fest, um die Funktionsauswahl zu deaktivieren.</span><span class="sxs-lookup"><span data-stu-id="b175a-203">Set this value to 0 to turn off feature selection.</span></span>  
  
 <span data-ttu-id="b175a-204">[Nur in einigen Editionen von [!INCLUDE[ssNoVersion](../../includes/ssnoversion-md.md)]verfügbar]</span><span class="sxs-lookup"><span data-stu-id="b175a-204">[Available only in some editions of [!INCLUDE[ssNoVersion](../../includes/ssnoversion-md.md)]]</span></span>  
  
 <span data-ttu-id="b175a-205">*MAXIMUM_OUTPUT_ATTRIBUTES*</span><span class="sxs-lookup"><span data-stu-id="b175a-205">*MAXIMUM_OUTPUT_ATTRIBUTES*</span></span>  
 <span data-ttu-id="b175a-206">Definiert die Anzahl von Ausgabeattributen, die der Algorithmus verarbeiten kann, bevor die Funktionsauswahl aufgerufen wird.</span><span class="sxs-lookup"><span data-stu-id="b175a-206">Defines the number of output attributes that the algorithm can handle before it invokes feature selection.</span></span>  
  
 <span data-ttu-id="b175a-207">Der Standardwert ist 255.</span><span class="sxs-lookup"><span data-stu-id="b175a-207">The default is 255.</span></span>  
  
 <span data-ttu-id="b175a-208">Legen Sie diesen Wert auf 0 fest, um die Funktionsauswahl zu deaktivieren.</span><span class="sxs-lookup"><span data-stu-id="b175a-208">Set this value to 0 to turn off feature selection.</span></span>  
  
 <span data-ttu-id="b175a-209">[Nur in einigen Editionen von [!INCLUDE[ssNoVersion](../../includes/ssnoversion-md.md)]verfügbar]</span><span class="sxs-lookup"><span data-stu-id="b175a-209">[Available only in some editions of [!INCLUDE[ssNoVersion](../../includes/ssnoversion-md.md)]]</span></span>  
  
 <span data-ttu-id="b175a-210">*MINIMUM_SUPPORT*</span><span class="sxs-lookup"><span data-stu-id="b175a-210">*MINIMUM_SUPPORT*</span></span>  
 <span data-ttu-id="b175a-211">Bestimmt die Mindestanzahl von Blattfällen, die zum Generieren einer Teilung in der Entscheidungsstruktur erforderlich sind.</span><span class="sxs-lookup"><span data-stu-id="b175a-211">Determines the minimum number of leaf cases that is required to generate a split in the decision tree.</span></span>  
  
 <span data-ttu-id="b175a-212">Der Standardwert ist 10.</span><span class="sxs-lookup"><span data-stu-id="b175a-212">The default is 10.</span></span>  
  
 <span data-ttu-id="b175a-213">Sie müssen möglicherweise diesen Wert erhöhen, wenn das Dataset sehr groß ist, um übermäßiges Trainieren zu vermeiden.</span><span class="sxs-lookup"><span data-stu-id="b175a-213">You may need to increase this value if the dataset is very large, to avoid overtraining.</span></span>  
  
 <span data-ttu-id="b175a-214">*SCORE_METHOD*</span><span class="sxs-lookup"><span data-stu-id="b175a-214">*SCORE_METHOD*</span></span>  
 <span data-ttu-id="b175a-215">Bestimmt die zum Berechnen des Teilungsergebnisses zu verwendende Methode.</span><span class="sxs-lookup"><span data-stu-id="b175a-215">Determines the method that is used to calculate the split score.</span></span> <span data-ttu-id="b175a-216">Die folgenden Optionen sind verfügbar:</span><span class="sxs-lookup"><span data-stu-id="b175a-216">The following options are available:</span></span>  
  
|<span data-ttu-id="b175a-217">id</span><span class="sxs-lookup"><span data-stu-id="b175a-217">ID</span></span>|<span data-ttu-id="b175a-218">Name</span><span class="sxs-lookup"><span data-stu-id="b175a-218">Name</span></span>|  
|--------|----------|  
|<span data-ttu-id="b175a-219">1</span><span class="sxs-lookup"><span data-stu-id="b175a-219">1</span></span>|<span data-ttu-id="b175a-220">Entropie</span><span class="sxs-lookup"><span data-stu-id="b175a-220">Entropy</span></span>|  
|<span data-ttu-id="b175a-221">3</span><span class="sxs-lookup"><span data-stu-id="b175a-221">3</span></span>|<span data-ttu-id="b175a-222">Bayes-Methode mit K2-A-priori-Verteilung</span><span class="sxs-lookup"><span data-stu-id="b175a-222">Bayesian with K2 Prior</span></span>|  
|<span data-ttu-id="b175a-223">4</span><span class="sxs-lookup"><span data-stu-id="b175a-223">4</span></span>|<span data-ttu-id="b175a-224">Bayes-Dirichlet-Äquivalent (BDE) mit uniformer A-priori-Verteilung</span><span class="sxs-lookup"><span data-stu-id="b175a-224">Bayesian Dirichlet Equivalent (BDE) with uniform prior</span></span><br /><br /> <span data-ttu-id="b175a-225">(Standard)</span><span class="sxs-lookup"><span data-stu-id="b175a-225">(default)</span></span>|  
  
 <span data-ttu-id="b175a-226">Der Standardwert ist 4 oder BDE.</span><span class="sxs-lookup"><span data-stu-id="b175a-226">The default is 4, or BDE.</span></span>  
  
 <span data-ttu-id="b175a-227">Eine Erläuterung dieser Bewertungsmethoden finden Sie unter [Feature Selection](../../sql-server/install/feature-selection.md).</span><span class="sxs-lookup"><span data-stu-id="b175a-227">For an explanation of these scoring methods, see [Feature Selection](../../sql-server/install/feature-selection.md).</span></span>  
  
 <span data-ttu-id="b175a-228">*SPLIT_METHOD*</span><span class="sxs-lookup"><span data-stu-id="b175a-228">*SPLIT_METHOD*</span></span>  
 <span data-ttu-id="b175a-229">Bestimmt die zum Teilen des Knotens zu verwendende Methode.</span><span class="sxs-lookup"><span data-stu-id="b175a-229">Determines the method that is used to split the node.</span></span> <span data-ttu-id="b175a-230">Die folgenden Optionen sind verfügbar:</span><span class="sxs-lookup"><span data-stu-id="b175a-230">The following options are available:</span></span>  
  
|<span data-ttu-id="b175a-231">id</span><span class="sxs-lookup"><span data-stu-id="b175a-231">ID</span></span>|<span data-ttu-id="b175a-232">Name</span><span class="sxs-lookup"><span data-stu-id="b175a-232">Name</span></span>|  
|--------|----------|  
|<span data-ttu-id="b175a-233">1</span><span class="sxs-lookup"><span data-stu-id="b175a-233">1</span></span>|<span data-ttu-id="b175a-234">**Binary:** Gibt an, dass die Struktur unabhängig von der tatsächlichen Anzahl der Werte für das Attribut in zwei Verzweigungen aufgeteilt werden soll.</span><span class="sxs-lookup"><span data-stu-id="b175a-234">**Binary:** Indicates that regardless of the actual number of values for the attribute, the tree should be split into two branches.</span></span>|  
|<span data-ttu-id="b175a-235">2</span><span class="sxs-lookup"><span data-stu-id="b175a-235">2</span></span>|<span data-ttu-id="b175a-236">**Complete:** Gibt an, dass die Struktur so viele Teilungen erstellen kann, wie Attributwerte vorhanden sind.</span><span class="sxs-lookup"><span data-stu-id="b175a-236">**Complete:** Indicates that the tree can create as many splits as there are attribute values.</span></span>|  
|<span data-ttu-id="b175a-237">3</span><span class="sxs-lookup"><span data-stu-id="b175a-237">3</span></span>|<span data-ttu-id="b175a-238">**Both:** Gibt an, dass Analysis Services bestimmen kann, ob eine binäre oder vollständige Teilung verwendet werden soll, um die besten Ergebnisse zu erzielen.</span><span class="sxs-lookup"><span data-stu-id="b175a-238">**Both:** Specifies that Analysis Services can determine whether a binary or complete split should be used to produce the best results.</span></span>|  
  
 <span data-ttu-id="b175a-239">Der Standardwert ist 3.</span><span class="sxs-lookup"><span data-stu-id="b175a-239">The default is 3.</span></span>  
  
### <a name="modeling-flags"></a><span data-ttu-id="b175a-240">Modellierungsflags</span><span class="sxs-lookup"><span data-stu-id="b175a-240">Modeling Flags</span></span>  
 <span data-ttu-id="b175a-241">Der [!INCLUDE[msCoName](../../includes/msconame-md.md)] Decision Tree-Algorithmus unterstützt die folgenden Modellierungsflags.</span><span class="sxs-lookup"><span data-stu-id="b175a-241">The [!INCLUDE[msCoName](../../includes/msconame-md.md)] Decision Trees algorithm supports the following modeling flags.</span></span> <span data-ttu-id="b175a-242">Wenn Sie die Miningstruktur oder das Miningmodell erstellen, definieren Sie Modellierungsflags, die angeben, wie die Werte in den einzelnen Spalten während der Analyse behandelt werden.</span><span class="sxs-lookup"><span data-stu-id="b175a-242">When you create the mining structure or mining model, you define modeling flags to specify how values in each column are handled during analysis.</span></span> <span data-ttu-id="b175a-243">Weitere Informationen finden Sie unter [Modellierungsflags &#40;Data Mining&#41;](modeling-flags-data-mining.md).</span><span class="sxs-lookup"><span data-stu-id="b175a-243">For more information, see [Modeling Flags &#40;Data Mining&#41;](modeling-flags-data-mining.md).</span></span>  
  
|<span data-ttu-id="b175a-244">Modellierungsflag</span><span class="sxs-lookup"><span data-stu-id="b175a-244">Modeling Flag</span></span>|<span data-ttu-id="b175a-245">BESCHREIBUNG</span><span class="sxs-lookup"><span data-stu-id="b175a-245">Description</span></span>|  
|-------------------|-----------------|  
|<span data-ttu-id="b175a-246">MODEL_EXISTENCE_ONLY</span><span class="sxs-lookup"><span data-stu-id="b175a-246">MODEL_EXISTENCE_ONLY</span></span>|<span data-ttu-id="b175a-247">Dies bedeutet, dass die Spalte zwei mögliche Statuswerte haben kann: `Missing` und `Existing`.</span><span class="sxs-lookup"><span data-stu-id="b175a-247">Means that the column will be treated as having two possible states: `Missing` and `Existing`.</span></span> <span data-ttu-id="b175a-248">Ein NULL-Wert ist ein fehlender Wert.</span><span class="sxs-lookup"><span data-stu-id="b175a-248">A null is a missing value.</span></span><br /><br /> <span data-ttu-id="b175a-249">Gilt für die Miningmodellspalten.</span><span class="sxs-lookup"><span data-stu-id="b175a-249">Applies to mining model columns.</span></span>|  
|<span data-ttu-id="b175a-250">NOT NULL</span><span class="sxs-lookup"><span data-stu-id="b175a-250">NOT NULL</span></span>|<span data-ttu-id="b175a-251">Gibt an, dass die Spalte keinen NULL-Wert enthalten kann.</span><span class="sxs-lookup"><span data-stu-id="b175a-251">Indicates that the column cannot contain a null.</span></span> <span data-ttu-id="b175a-252">Ein Fehler tritt auf, wenn Analysis Services während des Modelltrainings einen NULL-Wert erkennt.</span><span class="sxs-lookup"><span data-stu-id="b175a-252">An error will result if Analysis Services encounters a null during model training.</span></span><br /><br /> <span data-ttu-id="b175a-253">Gilt für die Miningstrukturspalten.</span><span class="sxs-lookup"><span data-stu-id="b175a-253">Applies to mining structure columns.</span></span>|  
  
### <a name="regressors-in-decision-tree-models"></a><span data-ttu-id="b175a-254">Regressoren in Entscheidungsstrukturmodellen</span><span class="sxs-lookup"><span data-stu-id="b175a-254">Regressors in Decision Tree Models</span></span>  
 <span data-ttu-id="b175a-255">Auch wenn Sie den [!INCLUDE[msCoName](../../includes/msconame-md.md)] Linear Regression-Algorithmus nicht verwenden, kann jedes Entscheidungsstrukturmodell, das über kontinuierliche numerische Eingaben und Ausgaben verfügt, potenziell Knoten enthalten, die eine Regression für ein kontinuierliches Attribut darstellen.</span><span class="sxs-lookup"><span data-stu-id="b175a-255">Even if you do not use the [!INCLUDE[msCoName](../../includes/msconame-md.md)] Linear Regression algorithm, any decision tree model that has continuous numeric inputs and outputs can potentially include nodes that represent a regression on a continuous attribute.</span></span>  
  
 <span data-ttu-id="b175a-256">Sie müssen nicht angeben, dass eine Spalte mit kontinuierlichen numerischen Daten einen Regressor darstellt.</span><span class="sxs-lookup"><span data-stu-id="b175a-256">You do not need to specify that a column of continuous numeric data represents a regressor.</span></span> <span data-ttu-id="b175a-257">Der [!INCLUDE[msCoName](../../includes/msconame-md.md)] Decision Trees-Algorithmus verwendet die Spalte automatisch als potenziellen Regressor und unterteilt das Dataset selbst dann in Bereiche mit sinnvollen Mustern, wenn Sie das REGRESSOR-Flag nicht für die Spalte festlegen.</span><span class="sxs-lookup"><span data-stu-id="b175a-257">The [!INCLUDE[msCoName](../../includes/msconame-md.md)] Decision Trees algorithm will automatically use the column as a potential regressor and partition the dataset into regions with meaningful patterns even if you do not set the REGRESSOR flag on the column.</span></span>  
  
 <span data-ttu-id="b175a-258">Sie können durch Einsatz des FORCE_REGRESSOR-Parameters jedoch gewährleisten, dass der Algorithmus einen bestimmten Regressor verwendet.</span><span class="sxs-lookup"><span data-stu-id="b175a-258">However, you can use the FORCE_REGRESSOR parameter to guarantee that the algorithm will use a particular regressor.</span></span> <span data-ttu-id="b175a-259">Dieser Parameter kann nur mit dem [!INCLUDE[msCoName](../../includes/msconame-md.md)] Decision Trees-Algorithmus und dem [!INCLUDE[msCoName](../../includes/msconame-md.md)] Linear Regression-Algorithmus verwendet werden.</span><span class="sxs-lookup"><span data-stu-id="b175a-259">This parameter can be used only with the [!INCLUDE[msCoName](../../includes/msconame-md.md)] Decision Trees and [!INCLUDE[msCoName](../../includes/msconame-md.md)] Linear Regression algorithms.</span></span> <span data-ttu-id="b175a-260">Wenn Sie das Modellierungsflag festlegen, versucht der Algorithmus Regressionsgleichungen der Form a \* C1 + b \* C2 +... , wenn die Muster in den Knoten der Struktur angepasst werden sollen.</span><span class="sxs-lookup"><span data-stu-id="b175a-260">When you set the modeling flag, the algorithm will try to find regression equations of the form a\*C1 + b\*C2 + ... to fit the patterns in the nodes of the tree.</span></span> <span data-ttu-id="b175a-261">Dann wird die Summe der Restwerte berechnet, und wenn die Abweichung zu groß ist, wird die Struktur unterteilt.</span><span class="sxs-lookup"><span data-stu-id="b175a-261">The sum of the residuals is calculated, and if the deviation is too great, a split is forced in the tree.</span></span>  
  
 <span data-ttu-id="b175a-262">Wenn Sie beispielsweise das Kaufverhalten von Kunden mithilfe des Attributs **Einkommen** vorhersagen und das Modellierungsflag REGRESSOR für die Spalte festlegen, versucht der Algorithmus zuerst, die Werte der Spalte **Einkommen** mithilfe einer Standardregressionsformel zuzuordnen.</span><span class="sxs-lookup"><span data-stu-id="b175a-262">For example, if you are predicting customer purchasing behavior using **Income** as an attribute, and set the REGRESSOR modeling flag on the column, the algorithm will first try to fit the **Income** values by using a standard regression formula.</span></span> <span data-ttu-id="b175a-263">Ist die Abweichung zu groß, dann wird die Regressionsformel ignoriert und die Struktur nach einem anderen Attribut unterteilt.</span><span class="sxs-lookup"><span data-stu-id="b175a-263">If the deviation is too great, the regression formula is abandoned and the tree will be split on another attribute.</span></span> <span data-ttu-id="b175a-264">Der Decision Tree-Algorithmus versucht nach der Unterteilung, jedem der Zweige einen Regressor für Einkommen zuzuordnen.</span><span class="sxs-lookup"><span data-stu-id="b175a-264">The decision tree algorithm will then try to fit a regressor for income in each of the branches after the split.</span></span>  
  
## <a name="requirements"></a><span data-ttu-id="b175a-265">Anforderungen</span><span class="sxs-lookup"><span data-stu-id="b175a-265">Requirements</span></span>  
 <span data-ttu-id="b175a-266">Ein Entscheidungsstrukturmodell muss eine Schlüsselspalte, Eingabespalten und mindestens eine vorhersagbare Spalte enthalten.</span><span class="sxs-lookup"><span data-stu-id="b175a-266">A decision tree model must contain a key column, input columns, and at least one predictable column.</span></span>  
  
### <a name="input-and-predictable-columns"></a><span data-ttu-id="b175a-267">Eingabespalten und vorhersagbare Spalten</span><span class="sxs-lookup"><span data-stu-id="b175a-267">Input and Predictable Columns</span></span>  
 <span data-ttu-id="b175a-268">Der [!INCLUDE[msCoName](../../includes/msconame-md.md)] Decision Trees-Algorithmus unterstützt bestimmte Eingabespalten und vorhersagbare Spalten. Diese sind in der nachstehenden Tabelle aufgelistet.</span><span class="sxs-lookup"><span data-stu-id="b175a-268">The [!INCLUDE[msCoName](../../includes/msconame-md.md)] Decision Trees algorithm supports the specific input columns and predictable columns that are listed in the following table.</span></span> <span data-ttu-id="b175a-269">Weitere Informationen zur Bedeutung der Inhaltstypen in einem Miningmodell finden Sie unter [Inhaltstypen &#40;Data Mining&#41;](content-types-data-mining.md).</span><span class="sxs-lookup"><span data-stu-id="b175a-269">For more information about what the content types mean when used in a mining model, see [Content Types &#40;Data Mining&#41;](content-types-data-mining.md).</span></span>  
  
|<span data-ttu-id="b175a-270">Column</span><span class="sxs-lookup"><span data-stu-id="b175a-270">Column</span></span>|<span data-ttu-id="b175a-271">Inhaltstypen</span><span class="sxs-lookup"><span data-stu-id="b175a-271">Content types</span></span>|  
|------------|-------------------|  
|<span data-ttu-id="b175a-272">Eingabeattribut</span><span class="sxs-lookup"><span data-stu-id="b175a-272">Input attribute</span></span>|<span data-ttu-id="b175a-273">Continuous, Cyclical, Discrete, Discretized, Key, Ordered, Table</span><span class="sxs-lookup"><span data-stu-id="b175a-273">Continuous, Cyclical, Discrete, Discretized, Key, Ordered, Table</span></span>|  
|<span data-ttu-id="b175a-274">Vorhersagbares Attribut</span><span class="sxs-lookup"><span data-stu-id="b175a-274">Predictable attribute</span></span>|<span data-ttu-id="b175a-275">Continuous, Cyclical, Discrete, Discretized, Ordered, Table</span><span class="sxs-lookup"><span data-stu-id="b175a-275">Continuous, Cyclical, Discrete, Discretized, Ordered, Table</span></span>|  
  
> [!NOTE]  
>  <span data-ttu-id="b175a-276">Zyklische und sortierte Inhaltstypen werden unterstützt, der Algorithmus behandelt sie jedoch als diskrete Werte und führt keine spezielle Verarbeitung durch.</span><span class="sxs-lookup"><span data-stu-id="b175a-276">Cyclical and Ordered content types are supported, but the algorithm treats them as discrete values and does not perform special processing.</span></span>  
  
## <a name="see-also"></a><span data-ttu-id="b175a-277">Weitere Informationen</span><span class="sxs-lookup"><span data-stu-id="b175a-277">See Also</span></span>  
 <span data-ttu-id="b175a-278">[Microsoft Decision Trees-Algorithmus](microsoft-decision-trees-algorithm.md) </span><span class="sxs-lookup"><span data-stu-id="b175a-278">[Microsoft Decision Trees Algorithm](microsoft-decision-trees-algorithm.md) </span></span>  
 <span data-ttu-id="b175a-279">[Beispiele für Entscheidungsstruktur-Modell Abfragen](decision-trees-model-query-examples.md) </span><span class="sxs-lookup"><span data-stu-id="b175a-279">[Decision Trees Model Query Examples](decision-trees-model-query-examples.md) </span></span>  
 [<span data-ttu-id="b175a-280">Miningmodellinhalt von Entscheidungsstrukturmodellen &#40;Analysis Services – Data Mining&#41;</span><span class="sxs-lookup"><span data-stu-id="b175a-280">Mining Model Content for Decision Tree Models &#40;Analysis Services - Data Mining&#41;</span></span>](mining-model-content-for-decision-tree-models-analysis-services-data-mining.md)  
  
  
